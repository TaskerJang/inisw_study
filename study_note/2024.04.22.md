```python
import seaborn as sns 
iris = sns.load_dataset('iris')
from sklearn.model_selection import train_test_split
len(train_test_split(iris))
2
train,test = train_test_split(iris)
len(train_test_split(iris.iloc[:,:-1], iris.species))
4
X_train,X_test,y_train,y_test = train_test_split(iris.iloc[:,:-1], iris.species, stratify=iris.species,
                                                test_size=0.4)
y_train.value_counts()
setosa        38
versicolor    37
virginica     37
Name: species, dtype: int64
import mglearn
mglearn.plot_cross_validation.plot_cross_validation()

from sklearn.datasets import load_iris
data = load_iris(as_frame=True)
iris = data.frame
iris.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 150 entries, 0 to 149
Data columns (total 5 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
 4   target             150 non-null    int32  
dtypes: float64(4), int32(1)
memory usage: 5.4 KB
X_train,X_test,y_train,y_test = train_test_split(iris.iloc[:,:-1], iris.target, stratify=iris.target,
                                                test_size=0.4)
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(5)
knn.get_params()
{'algorithm': 'auto',
 'leaf_size': 30,
 'metric': 'minkowski',
 'metric_params': None,
 'n_jobs': None,
 'n_neighbors': 20,
 'p': 2,
 'weights': 'uniform'}
for i in range(2,21):
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train,y_train)
    print(i, knn.score(X_test,y_test))
2 0.95
3 0.9666666666666667
4 0.9666666666666667
5 0.95
6 0.95
7 0.95
8 0.95
9 0.95
10 0.95
11 0.95
12 0.9333333333333333
13 0.95
14 0.95
15 0.95
16 0.95
17 0.95
18 0.9
19 0.9
20 0.9166666666666666
 
gnb = GaussianNB()
gnb.fit(X_train,y_train)

GaussianNB
GaussianNB()
sum(gnb.predict(X_test) == y_test) / len(y_test)
0.95
gnb.score(X_test,y_test)
0.95
from sklearn.model_selection import cross_val_score
cross_val_score(GaussianNB(), iris.iloc[:,:-1], iris.target, cv=5)
array([0.93333333, 0.96666667, 0.93333333, 0.93333333, 1.        ])
from sklearn.model_selection import learning_curve
len(learning_curve(GaussianNB(), iris.iloc[:,:-1], iris.target, cv=10))
3
from sklearn.linear_model import LogisticRegression
train_size, train_score, test_score = learning_curve(LogisticRegression(solver='newton-cg'), iris.iloc[:,:-1], iris.target, cv=10)
import sklearn_evaluation
sklearn_evaluation.plot.learning_curve(train_score, test_score, train_size)
<AxesSubplot:title={'center':'Learning Curve'}, xlabel='Training examples', ylabel='Score mean'>

 
```